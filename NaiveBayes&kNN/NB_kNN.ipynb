{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Min-max scaling of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       2      7      8     11     14     15     17     18     21     22  ...  \\\n",
      "0 -0.684 -0.113  0.401 -0.251 -0.178  0.321  0.016 -0.003 -0.275 -0.162  ...   \n",
      "1 -0.529 -0.066 -0.168 -0.205  0.020  0.031 -0.165 -0.026 -0.130  0.176  ...   \n",
      "2 -0.240  0.031 -0.077 -0.036 -0.005  0.170  0.212  0.138 -0.300  0.689  ...   \n",
      "3 -0.062 -0.143  0.068 -0.295 -0.188 -0.317 -0.113  0.018 -0.272 -0.531  ...   \n",
      "4 -0.203 -0.168  0.008  0.166 -0.048 -0.291 -0.091  0.062  0.026 -0.036  ...   \n",
      "\n",
      "      54     56     57     58     59     60     64     66     68  label  \n",
      "0 -0.263 -0.075 -0.327 -0.198 -0.257 -0.205 -0.223 -0.136 -0.132      0  \n",
      "1 -0.064  0.004 -0.305 -0.018 -0.230 -0.150 -0.151 -0.031 -0.097      0  \n",
      "2 -0.149  0.102 -0.189 -0.112 -0.121  0.121 -0.172  0.033 -0.321      0  \n",
      "3 -0.245 -0.153 -0.405 -0.102 -0.120 -0.141 -0.292 -0.078 -0.151      0  \n",
      "4  0.043 -0.099 -0.188  0.042 -0.124 -0.097 -0.165 -0.112 -0.138      1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# For reproducibility of results\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the dataset if selected_features.csv does not exist\n",
    "if os.path.exists(\"selected_features.csv\"):\n",
    "    selected_features = pd.read_csv(\"selected_features.csv\")\n",
    "    print(selected_features.head())\n",
    "else:\n",
    "    file_path = \"../DataProcessing/rtfDataSet.csv\"\n",
    "    original_data = pd.read_csv(file_path)\n",
    "    # Get only our features of interest and save them to a local file \"selecte_features.csv\"\n",
    "    # 2 7 8 11 14 15 17 18 21 22 23 25 30 31 33 36 40 43 44 50 53 54 56 57 58 59 60 64 66 68 and label\n",
    "    selected_features = original_data.iloc[:, [2, 7, 8, 11, 14, 15, 17, 18, 21, 22, 23, 25, 30, 31, 33, 36, 40, 43, 44, 50, 53, 54, 56, 57, 58, 59, 60, 64, 66, 68,70]]    \n",
    "    # Save the selected features to a local file\n",
    "    selected_features.to_csv(\"selected_features.csv\", index=False)\n",
    "    print(original_data.head())\n",
    "    print(selected_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            2         7         8        11        14        15        17  \\\n",
       " 0   -0.684000 -0.113000  0.401000 -0.251000 -0.178000  0.321000  0.016000   \n",
       " 1   -0.529000 -0.066000 -0.168000 -0.205000  0.020000  0.031000 -0.165000   \n",
       " 2   -0.240000  0.031000 -0.077000 -0.036000 -0.005000  0.170000  0.212000   \n",
       " 3   -0.062000 -0.143000  0.068000 -0.295000 -0.188000 -0.317000 -0.113000   \n",
       " 4   -0.203000 -0.168000  0.008000  0.166000 -0.048000 -0.291000 -0.091000   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 391 -0.240811  0.160049 -0.172790  0.431347  0.430861 -0.305451 -0.119770   \n",
       " 392 -0.179418 -0.000023 -0.260852  0.237564 -0.080075 -0.354038 -0.004051   \n",
       " 393 -0.553610 -0.005744 -0.068708 -0.253044  0.017528 -0.070628 -0.172178   \n",
       " 394  0.203276 -0.036268 -0.253699  0.382949  0.295444  0.049701 -0.245894   \n",
       " 395 -0.221108  0.450663 -0.293762  0.042793  0.153844 -0.268618 -0.083691   \n",
       " \n",
       "            18        21        22  ...        53        54        56  \\\n",
       " 0   -0.003000 -0.275000 -0.162000  ... -0.334000 -0.263000 -0.075000   \n",
       " 1   -0.026000 -0.130000  0.176000  ...  0.216000 -0.064000  0.004000   \n",
       " 2    0.138000 -0.300000  0.689000  ... -0.027000 -0.149000  0.102000   \n",
       " 3    0.018000 -0.272000 -0.531000  ...  0.389000 -0.245000 -0.153000   \n",
       " 4    0.062000  0.026000 -0.036000  ...  0.032000  0.043000 -0.099000   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 391 -0.118006  0.160183 -0.901993  ... -0.306867  0.214024  0.228945   \n",
       " 392 -0.026284 -0.041484  0.033320  ... -0.285406  0.022806 -0.073043   \n",
       " 393 -0.100074 -0.106106 -0.846611  ... -0.366089 -0.098186 -0.101396   \n",
       " 394 -0.095935  0.080918 -0.853218  ... -0.412803  0.245236  0.161970   \n",
       " 395 -0.237877 -0.046952 -0.991846  ...  0.003608 -0.018608  0.133373   \n",
       " \n",
       "            57        58        59        60        64        66        68  \n",
       " 0   -0.327000 -0.198000 -0.257000 -0.205000 -0.223000 -0.136000 -0.132000  \n",
       " 1   -0.305000 -0.018000 -0.230000 -0.150000 -0.151000 -0.031000 -0.097000  \n",
       " 2   -0.189000 -0.112000 -0.121000  0.121000 -0.172000  0.033000 -0.321000  \n",
       " 3   -0.405000 -0.102000 -0.120000 -0.141000 -0.292000 -0.078000 -0.151000  \n",
       " 4   -0.188000  0.042000 -0.124000 -0.097000 -0.165000 -0.112000 -0.138000  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 391  0.206469 -0.081721  0.104964  0.352103  0.319949  0.160157 -0.052955  \n",
       " 392 -0.207927 -0.091690 -0.157788 -0.137062 -0.001237 -0.015542  0.175237  \n",
       " 393  0.115763 -0.169348 -0.001617  0.531042 -0.260318 -0.063138 -0.627228  \n",
       " 394  0.013784  0.061287 -0.004070  0.369111  0.117017  0.084721  0.167364  \n",
       " 395 -0.347922  0.001645 -0.137182  0.173900 -0.153887 -0.058649  0.089997  \n",
       " \n",
       " [396 rows x 30 columns],\n",
       " 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      1\n",
       "       ..\n",
       " 391    1\n",
       " 392    1\n",
       " 393    1\n",
       " 394    1\n",
       " 395    1\n",
       " Name: label, Length: 396, dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = selected_features.iloc[:, -1]\n",
    "features = selected_features.iloc[:, :-1]\n",
    "\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18304732, 0.49900892, 0.89076305, ..., 0.33932274, 0.34881517,\n",
       "        0.52682455],\n",
       "       [0.26365055, 0.52229931, 0.43373494, ..., 0.38908086, 0.44834123,\n",
       "        0.54374094],\n",
       "       [0.41393656, 0.5703667 , 0.50682731, ..., 0.37456807, 0.50900474,\n",
       "        0.43547608],\n",
       "       ...,\n",
       "       [0.25085283, 0.55215857, 0.51348755, ..., 0.31353283, 0.41787867,\n",
       "        0.28746834],\n",
       "       [0.6444493 , 0.53703271, 0.3649004 , ..., 0.57430339, 0.55802938,\n",
       "        0.67151474],\n",
       "       [0.42376079, 0.77832656, 0.33272129, ..., 0.38708569, 0.42213365,\n",
       "        0.63412131]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "dataset_normalized = scaler.fit_transform(features)\n",
    "dataset_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def naive_bayes_classifier(X_train, y_train, X_test, y_test):\n",
    "    # Initialize and fit the Naive Bayes model\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = nb.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    pre = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return [acc, pre, rec, auc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_classifier(X_train, y_train, X_test, y_test, k_values, distance_metrics):\n",
    "    best_metrics = {}\n",
    "    \n",
    "    for metric in distance_metrics:\n",
    "        best_k = None\n",
    "        best_acc = 0\n",
    "        \n",
    "        for k in k_values:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(X_test)\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_k = k\n",
    "                \n",
    "        # Use the best k to calculate metrics\n",
    "        knn = KNeighborsClassifier(n_neighbors=best_k, metric=metric)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        pre = precision_score(y_test, y_pred)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "        best_metrics[metric] = [acc, pre, rec, auc]\n",
    "        \n",
    "    return best_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize empty lists to store metrics\n",
    "nb_metrics = []\n",
    "knn_metrics = []\n",
    "\n",
    "# Initialize lists to store metrics for averaging and standard deviation\n",
    "nb_acc_list, nb_pre_list, nb_rec_list, nb_auc_list = [], [], [], []\n",
    "knn_acc_list, knn_pre_list, knn_rec_list, knn_auc_list = [], [], [], []\n",
    "\n",
    "# Initialize StratifiedKFold and other variables\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "X = dataset_normalized\n",
    "y = labels\n",
    "k_values = list(range(1, 16, 2))\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "# Stratified 10-Fold CV\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Naive Bayes metrics\n",
    "    nb_metrics_current = naive_bayes_classifier(X_train, y_train, X_test, y_test)\n",
    "    nb_acc, nb_pre, nb_rec, nb_auc = nb_metrics_current\n",
    "    \n",
    "    # Append to lists for Naive Bayes\n",
    "    nb_acc_list.append(nb_acc)\n",
    "    nb_pre_list.append(nb_pre)\n",
    "    nb_rec_list.append(nb_rec)\n",
    "    nb_auc_list.append(nb_auc)\n",
    "\n",
    "    # k-Nearest Neighbors metrics\n",
    "    knn_result = knn_classifier(X_train, y_train, X_test, y_test, k_values, distance_metrics)\n",
    "    for metric, metric_values in knn_result.items():\n",
    "        knn_acc, knn_pre, knn_rec, knn_auc = metric_values\n",
    "        knn_metrics.append(metric_values)\n",
    "        \n",
    "        # Append to lists for kNN\n",
    "        knn_acc_list.append(knn_acc)\n",
    "        knn_pre_list.append(knn_pre)\n",
    "        knn_rec_list.append(knn_rec)\n",
    "        knn_auc_list.append(knn_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Average Accuracy: 0.6820512820512821, Std: 0.07965552891865686\n",
      "Naive Bayes Average Precision: 0.6940705071502284, Std: 0.0902119565080107\n",
      "Naive Bayes Average Recall: 0.6830952380952382, Std: 0.10870527464062577\n",
      "Naive Bayes Average AUC: 0.6820739348370928, Std: 0.07974708555709994\n",
      "kNN Average Accuracy: 0.7817948717948718, Std: 0.056898527854926585\n",
      "kNN Average Precision: 0.7085877926618243, Std: 0.059667736418086696\n",
      "kNN Average Recall: 0.985, Std: 0.03201562118716424\n",
      "kNN Average AUC: 0.7780263157894737, Std: 0.05595138496252241\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# After the loop ends, calculate average and standard deviation for each metric\n",
    "# For Naive Bayes\n",
    "avg_nb_acc, std_nb_acc = np.mean(nb_acc_list), np.std(nb_acc_list)\n",
    "avg_nb_pre, std_nb_pre = np.mean(nb_pre_list), np.std(nb_pre_list)\n",
    "avg_nb_rec, std_nb_rec = np.mean(nb_rec_list), np.std(nb_rec_list)\n",
    "avg_nb_auc, std_nb_auc = np.mean(nb_auc_list), np.std(nb_auc_list)\n",
    "\n",
    "# For kNN\n",
    "avg_knn_acc, std_knn_acc = np.mean(knn_acc_list), np.std(knn_acc_list)\n",
    "avg_knn_pre, std_knn_pre = np.mean(knn_pre_list), np.std(knn_pre_list)\n",
    "avg_knn_rec, std_knn_rec = np.mean(knn_rec_list), np.std(knn_rec_list)\n",
    "avg_knn_auc, std_knn_auc = np.mean(knn_auc_list), np.std(knn_auc_list)\n",
    "\n",
    "# Print or store these values for interpretation\n",
    "print(f\"Naive Bayes Average Accuracy: {avg_nb_acc}, Std: {std_nb_acc}\")\n",
    "print(f\"Naive Bayes Average Precision: {avg_nb_pre}, Std: {std_nb_pre}\")\n",
    "print(f\"Naive Bayes Average Recall: {avg_nb_rec}, Std: {std_nb_rec}\")\n",
    "print(f\"Naive Bayes Average AUC: {avg_nb_auc}, Std: {std_nb_auc}\")\n",
    "\n",
    "print(f\"kNN Average Accuracy: {avg_knn_acc}, Std: {std_knn_acc}\")\n",
    "print(f\"kNN Average Precision: {avg_knn_pre}, Std: {std_knn_pre}\")\n",
    "print(f\"kNN Average Recall: {avg_knn_rec}, Std: {std_knn_rec}\")\n",
    "print(f\"kNN Average AUC: {avg_knn_auc}, Std: {std_knn_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Naive Bayes Accuracy: 0.8205128205128205\n",
      "Best Naive Bayes Precision: 0.8823529411764706\n",
      "Best Naive Bayes Recall: 0.85\n",
      "Best Naive Bayes AUC: 0.8223684210526316\n",
      "Best kNN Accuracy: 0.8974358974358975\n",
      "Best kNN Precision: 0.8333333333333334\n",
      "Best kNN Recall: 1.0\n",
      "Best kNN AUC: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# Find and print the best metrics for Naive Bayes\n",
    "best_nb_acc = max(nb_acc_list)\n",
    "best_nb_pre = max(nb_pre_list)\n",
    "best_nb_rec = max(nb_rec_list)\n",
    "best_nb_auc = max(nb_auc_list)\n",
    "\n",
    "print(f\"Best Naive Bayes Accuracy: {best_nb_acc}\")\n",
    "print(f\"Best Naive Bayes Precision: {best_nb_pre}\")\n",
    "print(f\"Best Naive Bayes Recall: {best_nb_rec}\")\n",
    "print(f\"Best Naive Bayes AUC: {best_nb_auc}\")\n",
    "\n",
    "# Find and print the best metrics for kNN\n",
    "best_knn_acc = max(knn_acc_list)\n",
    "best_knn_pre = max(knn_pre_list)\n",
    "best_knn_rec = max(knn_rec_list)\n",
    "best_knn_auc = max(knn_auc_list)\n",
    "\n",
    "print(f\"Best kNN Accuracy: {best_knn_acc}\")\n",
    "print(f\"Best kNN Precision: {best_knn_pre}\")\n",
    "print(f\"Best kNN Recall: {best_knn_rec}\")\n",
    "print(f\"Best kNN AUC: {best_knn_auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "URKU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
