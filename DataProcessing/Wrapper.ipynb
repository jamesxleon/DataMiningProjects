{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /Users/jamesleon/anaconda3/envs/URKU/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/jamesleon/anaconda3/envs/URKU/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/jamesleon/anaconda3/envs/URKU/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/jamesleon/anaconda3/envs/URKU/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/jamesleon/anaconda3/envs/URKU/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.11.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.536</td>\n",
       "      <td>0.292</td>\n",
       "      <td>-0.684</td>\n",
       "      <td>0.123</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.496</td>\n",
       "      <td>-0.298</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.362</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>0.178</td>\n",
       "      <td>-0.120</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.188</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.292</td>\n",
       "      <td>-0.663</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.155</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>-0.112</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0 -0.536  0.292 -0.684  0.123 -0.118  0.346 -0.308 -0.113  0.401 -0.399  ...   \n",
       "1 -0.496 -0.298 -0.529  0.073 -0.072  0.107 -0.316 -0.066 -0.168 -0.099  ...   \n",
       "2  0.008 -0.031 -0.240  0.178 -0.120  0.317 -0.481  0.031 -0.077  0.063  ...   \n",
       "3 -0.188 -0.180 -0.062 -0.104 -0.136 -0.061 -0.216 -0.143  0.068 -0.189  ...   \n",
       "4  0.038  0.155 -0.203 -0.088 -0.084 -0.164 -0.145 -0.168  0.008  0.143  ...   \n",
       "\n",
       "      61     62     63     64     65     66     67     68     69  label  \n",
       "0 -0.135 -0.063 -0.410 -0.223 -0.599 -0.136 -0.329 -0.132 -0.266      0  \n",
       "1  0.189  0.007 -0.362 -0.151 -0.338 -0.031 -0.159 -0.097 -0.131      0  \n",
       "2 -0.035  0.101 -0.098 -0.172 -0.290  0.033 -0.342 -0.321 -0.238      0  \n",
       "3  0.146 -0.145 -0.527 -0.292 -0.663 -0.078 -0.194 -0.151 -0.268      0  \n",
       "4  0.019 -0.084  0.164 -0.165 -0.126 -0.112  0.029 -0.138  0.148      1  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE #for balanced\n",
    "\n",
    "# For reproducibility of results\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'rtfDataSet.csv'\n",
    "original_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows of the original dataset\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294244</td>\n",
       "      <td>0.705043</td>\n",
       "      <td>0.183047</td>\n",
       "      <td>0.610883</td>\n",
       "      <td>0.287570</td>\n",
       "      <td>0.806475</td>\n",
       "      <td>0.179009</td>\n",
       "      <td>0.499009</td>\n",
       "      <td>0.890763</td>\n",
       "      <td>0.184259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378264</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.300824</td>\n",
       "      <td>0.339323</td>\n",
       "      <td>0.180758</td>\n",
       "      <td>0.348815</td>\n",
       "      <td>0.324151</td>\n",
       "      <td>0.526825</td>\n",
       "      <td>0.128294</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.315761</td>\n",
       "      <td>0.143673</td>\n",
       "      <td>0.263651</td>\n",
       "      <td>0.559548</td>\n",
       "      <td>0.330241</td>\n",
       "      <td>0.630611</td>\n",
       "      <td>0.174344</td>\n",
       "      <td>0.522299</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.462037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606916</td>\n",
       "      <td>0.529530</td>\n",
       "      <td>0.333791</td>\n",
       "      <td>0.389081</td>\n",
       "      <td>0.332945</td>\n",
       "      <td>0.448341</td>\n",
       "      <td>0.433056</td>\n",
       "      <td>0.543741</td>\n",
       "      <td>0.221914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586875</td>\n",
       "      <td>0.397716</td>\n",
       "      <td>0.413937</td>\n",
       "      <td>0.667351</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.785136</td>\n",
       "      <td>0.078134</td>\n",
       "      <td>0.570367</td>\n",
       "      <td>0.506827</td>\n",
       "      <td>0.612037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448836</td>\n",
       "      <td>0.623624</td>\n",
       "      <td>0.515110</td>\n",
       "      <td>0.374568</td>\n",
       "      <td>0.360933</td>\n",
       "      <td>0.509005</td>\n",
       "      <td>0.315823</td>\n",
       "      <td>0.435476</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481442</td>\n",
       "      <td>0.255947</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.377823</td>\n",
       "      <td>0.270872</td>\n",
       "      <td>0.506990</td>\n",
       "      <td>0.232653</td>\n",
       "      <td>0.484143</td>\n",
       "      <td>0.623293</td>\n",
       "      <td>0.378704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576570</td>\n",
       "      <td>0.377377</td>\n",
       "      <td>0.220467</td>\n",
       "      <td>0.291638</td>\n",
       "      <td>0.143440</td>\n",
       "      <td>0.403791</td>\n",
       "      <td>0.410634</td>\n",
       "      <td>0.517641</td>\n",
       "      <td>0.126907</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603012</td>\n",
       "      <td>0.574691</td>\n",
       "      <td>0.433177</td>\n",
       "      <td>0.394251</td>\n",
       "      <td>0.319109</td>\n",
       "      <td>0.431199</td>\n",
       "      <td>0.274052</td>\n",
       "      <td>0.471754</td>\n",
       "      <td>0.575100</td>\n",
       "      <td>0.686111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486944</td>\n",
       "      <td>0.438438</td>\n",
       "      <td>0.695055</td>\n",
       "      <td>0.379406</td>\n",
       "      <td>0.456560</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>0.553491</td>\n",
       "      <td>0.523925</td>\n",
       "      <td>0.415395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.294244  0.705043  0.183047  0.610883  0.287570  0.806475  0.179009   \n",
       "1  0.315761  0.143673  0.263651  0.559548  0.330241  0.630611  0.174344   \n",
       "2  0.586875  0.397716  0.413937  0.667351  0.285714  0.785136  0.078134   \n",
       "3  0.481442  0.255947  0.506500  0.377823  0.270872  0.506990  0.232653   \n",
       "4  0.603012  0.574691  0.433177  0.394251  0.319109  0.431199  0.274052   \n",
       "\n",
       "          7         8         9  ...        61        62        63        64  \\\n",
       "0  0.499009  0.890763  0.184259  ...  0.378264  0.459459  0.300824  0.339323   \n",
       "1  0.522299  0.433735  0.462037  ...  0.606916  0.529530  0.333791  0.389081   \n",
       "2  0.570367  0.506827  0.612037  ...  0.448836  0.623624  0.515110  0.374568   \n",
       "3  0.484143  0.623293  0.378704  ...  0.576570  0.377377  0.220467  0.291638   \n",
       "4  0.471754  0.575100  0.686111  ...  0.486944  0.438438  0.695055  0.379406   \n",
       "\n",
       "         65        66        67        68        69  label  \n",
       "0  0.180758  0.348815  0.324151  0.526825  0.128294      0  \n",
       "1  0.332945  0.448341  0.433056  0.543741  0.221914      0  \n",
       "2  0.360933  0.509005  0.315823  0.435476  0.147712      0  \n",
       "3  0.143440  0.403791  0.410634  0.517641  0.126907      0  \n",
       "4  0.456560  0.371564  0.553491  0.523925  0.415395      1  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the data using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = pd.DataFrame(scaler.fit_transform(original_data.iloc[:,:-1]), columns=original_data.columns[:-1]) # Normalize all data except for the last column (label)\n",
    "normalized_data['label'] = original_data['label']\n",
    "\n",
    "save_csv = 'normalized_dataset.csv'\n",
    "normalized_data.to_csv(save_csv, index=False)\n",
    "\n",
    "# # argmax and argmin of normalized_data\n",
    "# normalized_data.idxmax(), normalized_data.idxmin()\n",
    "# normalized_data['label'][198]\n",
    "\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalized dataset (This can be adjusted to the working dataset in case there is some matching problems)\n",
    "file_path = 'normalized_dataset.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features (X) and labels (y)\n",
    "x = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Apply SMOTE to balance the dataset // Great job using a seed\n",
    "smote = SMOTE(random_state=42) \n",
    "x_balanced, y_balanced = smote.fit_resample(x, y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "x_balanced = scaler.fit_transform(x_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of iterations for Simulated Annealing\n",
    "n_iterations = 2000\n",
    "\n",
    "# Initialize the best solution and its score\n",
    "best_solution = None\n",
    "best_score = 0\n",
    "\n",
    "# Initialize the current solution and its score\n",
    "current_solution = pd.DataFrame(x_balanced, columns=x.columns)  # Use the balanced dataset\n",
    "current_score = 0\n",
    "\n",
    "# Define an initial temperature and cooling rate\n",
    "T_initial = 4.0  # Initial temperature\n",
    "alpha = 0.95  # Cooling rate\n",
    "\n",
    "# Define a small constant to avoid division by zero in the SU function\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Symmetrical Uncertainty function\n",
    "def symmetrical_uncertainty(x, y, epsilon):\n",
    "    mi = mutual_info_classif(x, y)\n",
    "    h_x = -np.sum(np.log2((x.sum() + epsilon) / (X.sum().sum() + epsilon)))\n",
    "    su = 2 * np.sum(mi) / h_x\n",
    "    return su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a list to store the importance scores for each subset\n",
    "subset_importance_scores = []\n",
    "\n",
    "# Simulated Annealing loop (this code could be improved)\n",
    "for iteration in range(n_iterations):\n",
    "    # Make a small random change to the current solution (feature selection)\n",
    "    feature_to_change = np.random.choice(current_solution.columns)\n",
    "    current_solution[feature_to_change] = np.random.choice([0, 1])\n",
    "    \n",
    "    # Calculate the Symmetrical Uncertainty score for the current solution\n",
    "    current_score = symmetrical_uncertainty(current_solution, y_balanced, epsilon=epsilon)\n",
    "    \n",
    "    # Calculate the change in score\n",
    "    delta_score = current_score - best_score\n",
    "    \n",
    "    # Accept the new solution with a certain probability based on the temperature\n",
    "    if delta_score > 0 or np.random.uniform() < np.exp(delta_score / T_initial):\n",
    "        best_solution = current_solution.copy()\n",
    "        best_score = current_score\n",
    "    \n",
    "    # Update the temperature using the cooling rate\n",
    "    T_initial *= alpha\n",
    "    \n",
    "    # Calculate the importance of the selected features in the current solution\n",
    "    selected_features = current_solution.columns[current_solution.sum() > 0]\n",
    "    importance_per_capita = current_score / len(selected_features)\n",
    "    subset_importance_scores.append(importance_per_capita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the selected features and their Symmetrical Uncertainty score\n",
    "selected_features = best_solution.columns[best_solution.sum() > 0]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n",
    "print(\"Symmetrical Uncertainty Score:\", best_score)\n",
    "\n",
    "# Calculate the importance per capita for the best solution\n",
    "best_importance_per_capita = best_score / len(selected_features)\n",
    "print(\"Importance Per Capita:\", best_importance_per_capita)\n",
    "\n",
    "# Plot the importance scores over iterations (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(n_iterations), subset_importance_scores)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Importance Per Capita\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 3. Top Five Feature Subsets\n",
    "\n",
    "# Use the feature selection method to identify the top five feature subsets\n",
    "# Calculate the per capita importance for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: 4. AUC Score-based Ranking\n",
    "\n",
    "# Use a classification model (e.g., logistic regression, SVM, etc.) to evaluate the feature subsets\n",
    "# Rank the top five feature subsets based on their AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: 5. Interpretation and Conclusion\n",
    "\n",
    "# Interpret the per capita importance and the AUC scores\n",
    "# Conclude the study, noting any limitations and suggesting future work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24e204bb5d77a0b46483d94efe4b4db5d97a985e2be6911fad4136740c833288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
